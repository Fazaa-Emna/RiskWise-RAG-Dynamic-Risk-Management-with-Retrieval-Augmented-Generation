{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LBrpkBBD-gB"
      },
      "source": [
        "#RAG Modeling Phase:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv9PbL1WL6I4"
      },
      "source": [
        "## Overview of Modeling Objective\n",
        "\n",
        "Hello from the **Firm AI Team**! After tirelessly preprocessing documents and building our conceptual graph (complete with colorful sticky notes and probably too much coffee), we saved the crème de la crème of our work on a Neo4j instance. And now, we’re excited to present our next thrilling adventure: building a **risk management-focused question-answer recommendation system**!\n",
        "\n",
        "This system will cleverly leverage our knowledge graph, which maps out relationships between concepts, risk factors, mitigation strategies, and other essential nodes relevant to project risk management. It’s like a treasure map but for tackling risks instead of pirates.\n",
        "\n",
        "### Key Points:\n",
        "\n",
        "- The system should recommend related risk factors, mitigation strategies, and definitions based on user queries about project risk management. Think of it as your personal risk management consultant, minus the hourly fees!\n",
        "- It will support risk reasoning and inference using graph-based deep learning techniques—because who doesn’t love a little reasoning with their risk?\n",
        "\n",
        "To achieve this, we’ll be utilizing **Graph Neural Networks (GNN)**, specifically GraphSAGE, alongside the exciting **RAG (Retrieval-Augmented Generation)** techniques. This means we’ll be creating rich node embeddings that reflect the relationships within our graph, allowing for intelligent recommendations that will help us navigate the often turbulent waters of project risk management.\n",
        "\n",
        "So, let’s dive in and see what treasures we can unearth!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO4KT6GxELGX"
      },
      "source": [
        "##Environemnet setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybm758jfKC-H",
        "outputId": "ab593340-c700-4ab9-d420-ed1a411faab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: neo4j in /usr/local/lib/python3.10/dist-packages (5.25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.dgl.ai/wheels/torch-2.4/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.9.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n",
            "Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting torch==2.5.1 (from torchvision)\n",
            "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1->torchvision)\n",
            "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0\n",
            "    Uninstalling torch-2.4.0:\n",
            "      Successfully uninstalled torch-2.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dgl 2.4.0 requires torch<=2.4.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the Hugging Face Transformers library for working with pre-trained models, including RoBERTa, for natural language processing tasks.\n",
        "!pip install transformers sentence-transformers\n",
        "\n",
        "# Install Neo4j Python driver for connecting to and interacting with the Neo4j graph database, along with Pandas for data manipulation and NetworkX for working with complex networks.\n",
        "!pip install neo4j pandas networkx\n",
        "\n",
        "# Install Deep Graph Library (DGL), which provides functionalities for building graph neural networks; this command specifies a custom repository compatible with PyTorch 2.4.\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/repo.html\n",
        "\n",
        "# Upgrade torchvision, a package that provides computer vision tools and models that can be used in conjunction with PyTorch.\n",
        "!pip install --upgrade torchvision\n",
        "\n",
        "# Install PyTorch, a deep learning library used for building and training neural networks, essential for model development in your project.\n",
        "!pip install torch\n",
        "\n",
        "# Install PyTorch Geometric, an extension library for deep learning on irregular structures like graphs, used for implementing graph neural networks and processing graph data.\n",
        "!pip install torch-geometric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QYt_Wc9pPQ80"
      },
      "outputs": [],
      "source": [
        "# Import the GraphDatabase class from the Neo4j driver to connect to and interact with the Neo4j graph database.\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Import Pandas for data manipulation and analysis, providing flexible data structures to work with.\n",
        "import pandas as pd\n",
        "\n",
        "# Import NetworkX for creating, manipulating, and studying the structure of complex networks and graphs.\n",
        "import networkx as nx\n",
        "\n",
        "# Import utility functions from PyTorch Geometric to convert NetworkX graphs into PyTorch Geometric data formats.\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# Import functional module from PyTorch for various activation functions and loss calculations.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import the SAGEConv layer from PyTorch Geometric, which implements the GraphSAGE model for graph neural networks.\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "# Import Data class from PyTorch Geometric to store graph data in a suitable format for processing.\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Import DataLoader from PyTorch Geometric for batching graph data during training and evaluation.\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Import PyTorch library for building and training neural network models.\n",
        "import torch\n",
        "\n",
        "# Import torchvision, a library that provides computer vision tools and datasets, typically used alongside PyTorch for image processing tasks.\n",
        "import torchvision\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "from torch_geometric.nn import DeepGraphInfomax, GCNConv # Import DGI as DeepGraphInfomax\n",
        "\n",
        "from torch_geometric.data import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KCddlCueg7"
      },
      "source": [
        "##Loading the knowledge graph from Neo4j instance\n",
        "**Retrieving graph data from a Neo4j database and formats it for use with PyTorch Geometric, facilitating further processing and analysis with graph neural networks.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6U-tQAgdTtfz"
      },
      "outputs": [],
      "source": [
        "# Connecting to our Neo4j instance\n",
        "uri = \"neo4j+s://30e67dcf.databases.neo4j.io\"\n",
        "username = \"neo4j\"  # Your Neo4j username\n",
        "password = \"No4yf_DI3pb2PfMLZUeUHRU4mIW2AA4UKEd9ySKR9HM\"  # Your Neo4j password"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QECfrt3d1Rc7"
      },
      "outputs": [],
      "source": [
        "driver = GraphDatabase.driver(uri, auth=(username, password))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TaO1ibYD0x2h"
      },
      "outputs": [],
      "source": [
        "# Fetch nodes and relationships from Neo4j\n",
        "def fetch_graph_from_neo4j():\n",
        "    with driver.session() as session:\n",
        "        # Fetch all terms (nodes) labeled as 'Term' from the graph\n",
        "        result = session.run(\"MATCH (n:Term) RETURN n.name AS name\")\n",
        "        # Store node names in a list\n",
        "        terms = [record[\"name\"] for record in result]\n",
        "\n",
        "        # Fetch directed edges between terms (relationships)\n",
        "        result = session.run(\"\"\"\n",
        "            MATCH (n:Term)-[r]->(m:Term) RETURN n.name AS source, m.name AS target\n",
        "        \"\"\")\n",
        "        # Store edges as tuples of (source, target)\n",
        "        edges = [(record[\"source\"], record[\"target\"]) for record in result]\n",
        "\n",
        "    return terms, edges\n",
        "\n",
        "# Convert Neo4j data to PyTorch Geometric format\n",
        "def convert_to_pyg_data(terms, edges):\n",
        "    # Create a mapping of node names to indices for easy referencing\n",
        "    node_index = {node: i for i, node in enumerate(terms)}\n",
        "\n",
        "    # Convert edges into a tensor format suitable for PyTorch Geometric (directed graph)\n",
        "    edge_index = torch.tensor([[node_index[src], node_index[tgt]] for src, tgt in edges], dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Create a one-hot encoded feature matrix for nodes (each term gets a unique vector)\n",
        "    x = torch.eye(len(terms))  # Each term is represented by a one-hot vector\n",
        "\n",
        "    # Return a PyTorch Geometric Data object containing node features and edge indices\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# Fetch the graph from Neo4j\n",
        "nodes, edges = fetch_graph_from_neo4j()\n",
        "\n",
        "# Convert fetched nodes and edges to PyTorch Geometric Data format\n",
        "data = convert_to_pyg_data(nodes, edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**=> Finally, the graph data is fetched and converted, preparing it for further processing in a graph neural network.**"
      ],
      "metadata": {
        "id": "K34sP1wPWMGn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0vKHqGF019"
      },
      "source": [
        "##Modeling Phase Using RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV83A1sMGp2g"
      },
      "source": [
        "### Retrieval-Augmented Generation (RAG) Modeling Workflow\n",
        "\n",
        "The RAG modeling process enhances the capabilities of a language model by integrating a knowledge graph. Below is the simplified workflow outlining the inputs and outputs at each stage:\n",
        "\n",
        "1. **Graph Embedding Generation**  \n",
        "   - **Input:**  \n",
        "     - Graph data, which includes nodes, edges, and their attributes.  \n",
        "   - **Output:**  \n",
        "     - Graph embeddings, which are numerical representations of the graph transformed into a latent space. These embeddings capture the relationships and features of the graph.\n",
        "\n",
        "2. **Retrieval Component**  \n",
        "   - **Input:**  \n",
        "     - User query, which is the question or information request from the user.  \n",
        "     - Graph embeddings generated in the previous step.  \n",
        "   - **Output:**  \n",
        "     - Relevant graph nodes and edges that provide contextual information related to the user query.\n",
        "\n",
        "3. **Generation Component**  \n",
        "   - **Input:**  \n",
        "     - Retrieved information (contextual data from the graph) that is relevant to the user query.  \n",
        "     - The original user query itself for context.  \n",
        "   - **Output:**  \n",
        "     - A generated response, which is the answer or information derived from the combination of the retrieved data and the user query.\n",
        "\n",
        "This structured workflow allows for efficient knowledge retrieval and intelligent answer generation based on the relationships and information embedded in the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWQTEz4zFfYV"
      },
      "source": [
        "###Graph Embeddings Generation: Using GCN with DGI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN-based DGI Overview\n",
        "\n",
        "GCN-based DGI (Graph Convolutional Network-based Deep Graph Infomax) is a neural network architecture designed for learning representations of graph-structured data. Below is a summary of its key components and significance:\n",
        "\n",
        "### Graph Convolutional Network (GCN)\n",
        "- **Definition**: GCNs are specialized neural networks that operate on graph data, generalizing the convolution operation to graph structures.\n",
        "- **Functionality**: They learn to represent nodes based on their features and the graph's structure, propagating information through convolutional layers that aggregate data from neighboring nodes.\n",
        "\n",
        "### Deep Graph Infomax (DGI)\n",
        "- **Definition**: DGI is a self-supervised learning framework that aims to learn node representations by maximizing mutual information between node embeddings and a global graph summary.\n",
        "- **Mechanism**: It distinguishes \"positive\" embeddings from the original graph and \"negative\" embeddings from corrupted versions, allowing the model to learn meaningful node representations.\n",
        "\n",
        "### GCN-based DGI Workflow\n",
        "\n",
        "1. **Input**: The model receives node features and graph structure (edges) as input, represented by an adjacency list or matrix.\n",
        "  \n",
        "2. **Encoding**: A GCN encoder processes these features through several layers, capturing local neighborhood structures to generate node embeddings.\n",
        "  \n",
        "3. **Corruption**: A corruption function shuffles or alters the node features, creating a corrupted graph used to generate negative samples for learning.\n",
        "  \n",
        "4. **Mutual Information Maximization**: The model aims to maximize mutual information between node embeddings and the graph summary, using a loss function that penalizes indistinguishable positive and negative samples.\n",
        "  \n",
        "5. **Training**: The model is trained over multiple epochs to develop informative embeddings that capture underlying graph structures and relationships.\n",
        "\n",
        "6. **Output**: After training, the model can produce embeddings for graph nodes, which are valuable for downstream tasks such as clustering, classification, or visualization."
      ],
      "metadata": {
        "id": "1dDH3RlrkF8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8X26kqyA1EvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76dc4f8e-96bd-4020-cc2a-2603b7da9397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.3824946880340576\n",
            "Epoch 10, Loss: 1.2581825256347656\n",
            "Epoch 20, Loss: 1.0719186067581177\n",
            "Epoch 30, Loss: 0.9790314435958862\n",
            "Epoch 40, Loss: 0.5851831436157227\n",
            "Epoch 50, Loss: 0.6526989340782166\n",
            "Epoch 60, Loss: 0.6309759020805359\n",
            "Epoch 70, Loss: 0.3330630958080292\n",
            "Epoch 80, Loss: 0.2401796281337738\n",
            "Epoch 90, Loss: 0.25281500816345215\n",
            "Node Embeddings: tensor([[ 0.0208, -0.0097,  0.0118,  ..., -0.1501,  0.1057,  0.2467],\n",
            "        [-0.0149, -0.0008,  0.0222,  ..., -0.1186,  0.0043,  0.1762],\n",
            "        [ 0.0798, -0.1107,  0.0487,  ...,  0.0127,  0.0929, -0.0110],\n",
            "        ...,\n",
            "        [ 0.0312, -0.0364,  0.0698,  ..., -0.0322,  0.0806,  0.1061],\n",
            "        [ 0.1472,  0.0237,  0.1115,  ...,  0.0441,  0.1263,  0.1603],\n",
            "        [ 0.1136,  0.0422,  0.0498,  ..., -0.0023,  0.1311,  0.1265]])\n"
          ]
        }
      ],
      "source": [
        "# Define the Graph Neural Network (GCN) encoder\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Corruption function (shuffles node features)\n",
        "def corruption(x, edge_index):\n",
        "    return x[torch.randperm(x.size(0))], edge_index\n",
        "\n",
        "# Initialize the DGI model\n",
        "in_channels = data.num_node_features  # Number of input features\n",
        "out_channels = 64  # Dimension of output embeddings\n",
        "encoder = GCNEncoder(in_channels, out_channels)\n",
        "model = DeepGraphInfomax(\n",
        "    hidden_channels=out_channels,\n",
        "    encoder=encoder,\n",
        "    summary=lambda z, *args: torch.sigmoid(z.mean(dim=0)),  # Summary function\n",
        "    corruption=corruption  # Corruption function\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pos_z, neg_z, summary = model(data.x, data.edge_index)\n",
        "    loss = model.loss(pos_z, neg_z, summary)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Train the model for some epochs\n",
        "for epoch in range(100):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "# Get the embeddings after training\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    node_embeddings = model(data.x, data.edge_index)[0]\n",
        "    print('Node Embeddings:',node_embeddings)\n",
        "\n",
        "# Close Neo4j connection\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS4CYxZK3fR4"
      },
      "source": [
        "### Evaluating the Graph Embeddings Generation with clustering and tsne score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # PyTorch is used for building and training neural networks and handling tensor operations efficiently.\n",
        "from sklearn.cluster import KMeans  # KMeans is a clustering algorithm used for partitioning data into distinct groups based on similarity.\n",
        "from sklearn.metrics import silhouette_score  # Silhouette score helps evaluate the quality of clusters by measuring how similar an object is to its own cluster compared to other clusters.\n",
        "from sklearn.manifold import TSNE  # t-SNE (t-distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique used to visualize high-dimensional data in lower dimensions.\n",
        "import matplotlib.pyplot as plt  # Matplotlib is a plotting library used for creating static, animated, and interactive visualizations in Python."
      ],
      "metadata": {
        "id": "wMbhXzt3W41L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-rzrHwa846n8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "1abf0f33-f3c4-454a-d4e0-397d292ad956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score for K-Means clustering: 0.1351\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# I start by setting the model to evaluation mode to ensure that layers like dropout and batch normalization function correctly.\n",
        "model.eval()\n",
        "\n",
        "# Next, I disable gradient tracking to improve efficiency since I don't need to compute gradients during inference.\n",
        "with torch.no_grad():\n",
        "    # I retrieve the node embeddings from the model using the input data.\n",
        "    embeddings = model(data.x, data.edge_index)[0]\n",
        "\n",
        "# After getting the embeddings, I move them to the CPU and convert them into a NumPy array for compatibility with other libraries.\n",
        "embeddings_np = embeddings.cpu().numpy()\n",
        "\n",
        "# Now, I will evaluate the embeddings using K-Means clustering.\n",
        "num_clusters = 5  # I've chosen to cluster the embeddings into 5 groups.\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)  # I initialize the K-Means algorithm with the specified number of clusters.\n",
        "# I fit the K-Means model to the embeddings and get the cluster labels for each node.\n",
        "cluster_labels = kmeans.fit_predict(embeddings_np)\n",
        "\n",
        "# To assess the quality of the clustering, I calculate the silhouette score, which indicates how well-defined the clusters are.\n",
        "silhouette_avg = silhouette_score(embeddings_np, cluster_labels)\n",
        "# I print the silhouette score to evaluate the clustering performance.\n",
        "print(f\"Silhouette Score for K-Means clustering: {silhouette_avg:.4f}\")\n",
        "\n",
        "# For further evaluation, I will visualize the embeddings using t-SNE.\n",
        "# I initialize the t-SNE algorithm to reduce the dimensionality of the embeddings to 2D.\n",
        "tsne = TSNE(n_components=2, perplexity=15, random_state=42)\n",
        "# I apply t-SNE to transform the high-dimensional embeddings into a 2D representation.\n",
        "embeddings_2d = tsne.fit_transform(embeddings_np)\n",
        "\n",
        "# I create a figure for the t-SNE plot with a specified size.\n",
        "plt.figure(figsize=(10, 8))\n",
        "# I generate a scatter plot of the 2D embeddings, using the cluster labels to color the points.\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.7)\n",
        "# I add a color bar to indicate the cluster assignments.\n",
        "plt.colorbar(label=\"Cluster\")\n",
        "# I label the axes for clarity.\n",
        "plt.xlabel(\"t-SNE Dimension 1\")\n",
        "plt.ylabel(\"t-SNE Dimension 2\")\n",
        "# I set a title for the plot to describe what is being shown.\n",
        "plt.title(\"t-SNE Visualization of Graph Embeddings\")\n",
        "# Finally, I display the plot to visualize the results.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w3UAg4JE99OK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa54b155-8555-48be-a1a8-7a8f44a1a954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Node Embeddings:\n",
            "(tensor([[ 0.0208, -0.0097,  0.0118,  ..., -0.1501,  0.1057,  0.2467],\n",
            "        [-0.0149, -0.0008,  0.0222,  ..., -0.1186,  0.0043,  0.1762],\n",
            "        [ 0.0798, -0.1107,  0.0487,  ...,  0.0127,  0.0929, -0.0110],\n",
            "        ...,\n",
            "        [ 0.0312, -0.0364,  0.0698,  ..., -0.0322,  0.0806,  0.1061],\n",
            "        [ 0.1472,  0.0237,  0.1115,  ...,  0.0441,  0.1263,  0.1603],\n",
            "        [ 0.1136,  0.0422,  0.0498,  ..., -0.0023,  0.1311,  0.1265]]), tensor([[ 0.1870, -0.1812,  0.2277,  ...,  0.2161,  0.4069,  0.1518],\n",
            "        [ 0.1393, -0.0882,  0.1428,  ...,  0.1127,  0.2473,  0.0974],\n",
            "        [ 0.1040, -0.2075,  0.1529,  ...,  0.0436,  0.1946,  0.1267],\n",
            "        ...,\n",
            "        [ 0.2267, -0.2139,  0.1723,  ...,  0.1106,  0.2293,  0.0822],\n",
            "        [ 0.3163, -0.2201,  0.1710,  ...,  0.2000,  0.3523,  0.0491],\n",
            "        [ 0.0730, -0.1305,  0.0311,  ..., -0.0233,  0.1801,  0.2021]]), tensor([0.5053, 0.4973, 0.5033, 0.4842, 0.5213, 0.5100, 0.5230, 0.5028, 0.5209,\n",
            "        0.4840, 0.4982, 0.5152, 0.4990, 0.5252, 0.5168, 0.5328, 0.5160, 0.5001,\n",
            "        0.5161, 0.5006, 0.5210, 0.4792, 0.5264, 0.5008, 0.4721, 0.4919, 0.4861,\n",
            "        0.5155, 0.5125, 0.5174, 0.5025, 0.5298, 0.5243, 0.5063, 0.5063, 0.4971,\n",
            "        0.5097, 0.4998, 0.5140, 0.4953, 0.5291, 0.5223, 0.5090, 0.5051, 0.5488,\n",
            "        0.5262, 0.5077, 0.4719, 0.4969, 0.5163, 0.4775, 0.5156, 0.4865, 0.5030,\n",
            "        0.4923, 0.5009, 0.5068, 0.5026, 0.5332, 0.5076, 0.5032, 0.4888, 0.5142,\n",
            "        0.5342]))\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index)  # Get the learned node embeddings\n",
        "    print(\"Final Node Embeddings:\")\n",
        "    print(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AihF8UteJmt4"
      },
      "source": [
        "###Generating User Query Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TjL4LZ69Iwd5"
      },
      "outputs": [],
      "source": [
        "# Function to generate a query embedding from related nodes\n",
        "def generate_query_embedding(query_text, node_embeddings, concept_terms):\n",
        "    # This function simulates getting a query embedding by averaging node embeddings\n",
        "    # It takes the query text and looks for related nodes\n",
        "\n",
        "    related_nodes = []\n",
        "    for idx, term in enumerate(concept_terms):\n",
        "        if term.lower() in query_text.lower():\n",
        "            related_nodes.append(node_embeddings[idx])\n",
        "\n",
        "    if len(related_nodes) > 0:\n",
        "        query_embedding = torch.stack(related_nodes).mean(dim=0)\n",
        "    else:\n",
        "        # If no related nodes found, use a random node embedding or zero tensor\n",
        "        query_embedding = torch.zeros(node_embeddings.size(1))\n",
        "\n",
        "    return query_embedding\n",
        "\n",
        "# Generate the query embedding\n",
        "concept_terms = [\"Risk Identification\", \"Risk Analysis\", \"Risk Response Planning\", \"Risk Monitoring\", \"Risk Communication\"]\n",
        "query = \"What strategies can help in risk mitigation during a project?\"\n",
        "query_embedding = generate_query_embedding(query, node_embeddings, concept_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3rNzBRqHC4V"
      },
      "source": [
        "### Retrieval Using Generated Node Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Once we have the query embeddings, we compare it to the node embeddings to find the closest matches (using cosine similarity). This allows us to retrieve relevant nodes or answers based on the user's query, enhancing the information retrieval capabilities of our system.**"
      ],
      "metadata": {
        "id": "ea5nCqIu7Z5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2kL6XNyMOaj7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from neo4j import GraphDatabase\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vDhFzgHXHFrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5c544d-d4f5-41ba-c88b-28c396b2edf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant Nodes: [39 38 17 16 15]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Retrieve nodes based on the generated query embedding\n",
        "def retrieve_relevant_nodes(query_embedding, node_embeddings, top_k=5):\n",
        "    # Calculate cosine similarity between the query embedding and all node embeddings\n",
        "    similarities = cosine_similarity(query_embedding.reshape(1, -1), node_embeddings)\n",
        "    top_indices = np.argsort(similarities[0])[::-1][:top_k]\n",
        "    return top_indices\n",
        "\n",
        "# Retrieve relevant nodes\n",
        "relevant_nodes = retrieve_relevant_nodes(query_embedding.numpy(), node_embeddings.numpy())\n",
        "print(\"Relevant Nodes:\", relevant_nodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Complete pipeline"
      ],
      "metadata": {
        "id": "DpY9ztzQn89y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is a complete workflow for fetching graph data from a Neo4j database, processing that data into a format suitable for training a Graph Convolutional Network (GCN), and then using the model to generate embeddings for nodes. The embeddings can then be used to retrieve relevant context for a user query using a question-answering (QA) pipeline from Hugging Face (Roberta).**"
      ],
      "metadata": {
        "id": "kRUPx1Os-Dj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m2Y0LE6VB7s2"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eVoSqunjbkm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5dcc9f-90ad-4528-8b2b-bbaee4f3fcf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 12, offset: 26} for query: '\\n    MATCH (n)\\n    RETURN ID(n) AS node_id, labels(n) AS labels, n.name AS name, n.definition AS definition, n.synonyms AS synonyms\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 12, offset: 35} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN ID(n) AS source_id, ID(m) AS target_id\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 32, offset: 55} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN ID(n) AS source_id, ID(m) AS target_id\\n    '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7757017016410828\n",
            "Epoch 10, Loss: 0.42391568422317505\n",
            "Epoch 20, Loss: 0.40881234407424927\n",
            "Epoch 30, Loss: 0.4112468361854553\n",
            "Epoch 40, Loss: 0.4136650860309601\n",
            "Epoch 50, Loss: 0.4058001935482025\n",
            "Epoch 60, Loss: 0.4293200969696045\n",
            "Epoch 70, Loss: 0.41999396681785583\n",
            "Epoch 80, Loss: 0.3895845413208008\n",
            "Epoch 90, Loss: 0.37761685252189636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query (or type 'exit' to quit):\n",
            "Your query: What is Project Risk Management?\n",
            "Based on your query 'What is Project Risk Management?', I found the following information: \n",
            "\n",
            "scope standard\n",
            "\n",
            "Additionally, here are some related topics that might interest you: \n",
            "benefit, analysis, information, Knowledge and Information, Quality and Program Management, Resource Management, quality, product, cycle, measure\n",
            "Your query: What are the tools to ensure risk management?\n",
            "Based on your query 'What are the tools to ensure risk management?', I found the following information: \n",
            "\n",
            "associate environment component value delivery system\n",
            "\n",
            "Additionally, here are some related topics that might interest you: \n",
            "schedule, development, Planning and Execution, resource, requirement, risk, scope, Risk Management, delivery, plan\n",
            "Your query: exit\n"
          ]
        }
      ],
      "source": [
        "from neo4j import GraphDatabase\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from transformers import pipeline\n",
        "\n",
        "# Establish connection to Neo4j\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Step 1: Fetch Data from Neo4j\n",
        "def fetch_graph_data():\n",
        "    nodes = {}\n",
        "    edge_index = []\n",
        "\n",
        "    # Fetch all nodes from Neo4j\n",
        "    node_query = \"\"\"\n",
        "    MATCH (n)\n",
        "    RETURN ID(n) AS node_id, labels(n) AS labels, n.name AS name, n.definition AS definition, n.synonyms AS synonyms\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        node_results = session.run(node_query)\n",
        "        for record in node_results:\n",
        "            node_id = record[\"node_id\"]\n",
        "            nodes[node_id] = {\n",
        "                \"name\": record.get(\"name\", \"\"),\n",
        "                \"definition\": record.get(\"definition\", \"\"),\n",
        "                \"synonyms\": record.get(\"synonyms\", []),\n",
        "                \"index\": len(nodes)  # Assign a unique index to each node\n",
        "            }\n",
        "\n",
        "    # Fetch all relationships from Neo4j\n",
        "    relationship_query = \"\"\"\n",
        "    MATCH (n)-[r]->(m)\n",
        "    RETURN ID(n) AS source_id, ID(m) AS target_id\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        relationship_results = session.run(relationship_query)\n",
        "        for record in relationship_results:\n",
        "            source_id = record[\"source_id\"]\n",
        "            target_id = record[\"target_id\"]\n",
        "\n",
        "            # Ensure that both source and target nodes are present in the graph\n",
        "            if source_id in nodes and target_id in nodes:\n",
        "                edge_index.append([nodes[source_id][\"index\"], nodes[target_id][\"index\"]])\n",
        "            else:\n",
        "                print(f\"Warning: Relationship between '{source_id}' and '{target_id}' refers to non-existent nodes.\")\n",
        "\n",
        "    return nodes, edge_index\n",
        "\n",
        "# Step 2: Prepare PyTorch Geometric Data\n",
        "def prepare_graph_data(nodes, edge_index):\n",
        "    # Define node features (for simplicity, using one-hot encoding for each node)\n",
        "    num_nodes = len(nodes)\n",
        "    features = torch.eye(num_nodes)  # One-hot encoding for each node\n",
        "\n",
        "    # Convert edge_index to tensor format\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Create the PyTorch Geometric Data object\n",
        "    data = Data(x=features, edge_index=edge_index)\n",
        "    return data\n",
        "\n",
        "# Fetch graph data from Neo4j\n",
        "nodes, edge_index = fetch_graph_data()\n",
        "data = prepare_graph_data(nodes, edge_index)\n",
        "\n",
        "# Step 3: Define the GCN Encoder Model\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and optimizer\n",
        "in_channels = data.num_node_features\n",
        "out_channels = 64  # Dimension of output embeddings\n",
        "model = GCNEncoder(in_channels, out_channels)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 4: Train the Model with Positive and Negative Edges\n",
        "def train_embedding_model(epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        z = model(data.x, data.edge_index)  # Forward pass to get node embeddings\n",
        "\n",
        "        # Use positive edges from edge_index\n",
        "        positive_edges = data.edge_index\n",
        "\n",
        "        # Generate negative samples (corrupted edges)\n",
        "        num_nodes = data.num_nodes\n",
        "        negative_edges = torch.randint(0, num_nodes, positive_edges.size(), dtype=torch.long)\n",
        "\n",
        "        # Compute positive and negative scores\n",
        "        pos_score = F.cosine_similarity(z[positive_edges[0]], z[positive_edges[1]])\n",
        "        neg_score = F.cosine_similarity(z[negative_edges[0]], z[negative_edges[1]])\n",
        "\n",
        "        # Max-margin loss\n",
        "        margin = 1.0\n",
        "        loss = torch.mean(F.relu(margin - pos_score + neg_score))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "    return z\n",
        "\n",
        "# Train the embedding model\n",
        "embeddings = train_embedding_model()\n",
        "\n",
        "# Step 5: Define the Retrieval Function with Rich Context Generation\n",
        "def retrieve_relevant_context(query_embedding, node_embeddings, nodes, k=10):\n",
        "    # Compute similarity between the query and node embeddings (cosine similarity)\n",
        "    similarity_scores = F.cosine_similarity(query_embedding.unsqueeze(0), node_embeddings)\n",
        "    top_k_indices = torch.topk(similarity_scores, k).indices\n",
        "\n",
        "    related_topics = [nodes[i][\"name\"] for i in top_k_indices if nodes[i][\"name\"]]\n",
        "    context_nodes = [nodes[i][\"definition\"] for i in top_k_indices if nodes[i][\"definition\"]]\n",
        "\n",
        "    context = \" \".join(context_nodes)\n",
        "    return context, related_topics\n",
        "\n",
        "# Example query embedding (you would typically generate this from a real query)\n",
        "query_embedding = embeddings[0]  # For demonstration purposes, use the first node embedding\n",
        "\n",
        "# Retrieve relevant nodes for context\n",
        "context, related_topics = retrieve_relevant_context(query_embedding, embeddings, list(nodes.values()))\n",
        "\n",
        "# Step 6: Use HuggingFace's Question-Answering Pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Function to answer a query using the Hugging Face model\n",
        "def answer_query_with_context(query, context, related_topics):\n",
        "    result = qa_pipeline(question=query, context=context)\n",
        "    response = f\"Based on your query '{query}', I found the following information: \\n\\n{result['answer']}\\n\"\n",
        "    response += \"\\nAdditionally, here are some related topics that might interest you: \\n\"\n",
        "    response += \", \".join(related_topics)\n",
        "    return response\n",
        "\n",
        "# Interactive Query Loop\n",
        "def interactive_query():\n",
        "    print(\"Enter your query (or type 'exit' to quit):\")\n",
        "    while True:\n",
        "        query = input(\"Your query: \")\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Generate a query embedding (for simplicity, using a random node's embedding)\n",
        "        query_embedding = embeddings[torch.randint(0, len(embeddings), (1,)).item()]\n",
        "\n",
        "        # Retrieve relevant nodes for context\n",
        "        context, related_topics = retrieve_relevant_context(query_embedding, embeddings, list(nodes.values()))\n",
        "\n",
        "        # Get the answer from the QA model\n",
        "        response = answer_query_with_context(query, context, related_topics)\n",
        "        print(response)\n",
        "\n",
        "# Example usage of the interactive function\n",
        "interactive_query()\n",
        "\n",
        "# Close the Neo4j connection\n",
        "driver.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enhancements to Graph-Based Model with Neo4j and PyTorch Geometric\n",
        "\n",
        "## Overview\n",
        "In this notebook, we have implemented several enhancements to our graph-based model that utilizes Neo4j for data retrieval and PyTorch Geometric for graph neural network (GNN) operations. These changes aim to improve the quality of node embeddings and the overall performance of the model in answering user queries.\n",
        "\n",
        "## Key Changes\n",
        "\n",
        "### 1. Data Fetching Improvements\n",
        "- **Expanded Node Information**: The query now retrieves additional attributes such as `name`, `definition`, `synonyms`, and `figure_descriptions`, which provide richer context for the nodes in the graph.\n",
        "- **Warnings for Missing Nodes**: Added checks and warnings for relationships that reference non-existent nodes, ensuring data integrity.\n",
        "\n",
        "### 2. Graph Data Preparation\n",
        "- **One-Hot Encoding for Features**: Each node is represented with a one-hot encoded feature vector, enhancing the model's ability to differentiate between nodes.\n",
        "\n",
        "### 3. GCN Encoder Enhancements\n",
        "- **Two Layers in GCN**: The GCN model architecture now includes two layers, allowing for increased feature dimensionality in the first layer (`2 * out_channels`), which helps capture more complex relationships in the graph.\n",
        "\n",
        "### 4. Training Process Adjustments\n",
        "- **Cosine Similarity for Scores**: We employ cosine similarity for scoring embeddings, providing a more effective measure of similarity in high-dimensional spaces.\n",
        "- **Max-margin Loss Calculation**: The training process incorporates both positive and negative samples in a max-margin loss function, promoting a more robust embedding space.\n",
        "\n",
        "### 5. Contextual Retrieval Function\n",
        "- **Rich Context Generation**: The `retrieve_relevant_context` function now returns detailed context (name, definition, synonyms, figure descriptions) for the most relevant nodes, enriching the information available for subsequent question-answering.\n",
        "\n",
        "## Conclusion\n",
        "These enhancements contribute to a more powerful and effective model capable of understanding and responding to user queries with relevant and contextual information derived from the graph structure. The improvements in data representation, model architecture, training methodology, and integration with advanced NLP tools position this model for better performance in real-world applications.\n"
      ],
      "metadata": {
        "id": "YPfadPVX_Dai"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2nszWoiMe2Rn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc92e601-74e9-40e3-96b4-40532ceaf078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 12, offset: 26} for query: '\\n    MATCH (n)\\n    RETURN ID(n) AS node_id, labels(n) AS labels, n.name AS name, n.definition AS definition, n.synonyms AS synonyms, n.figure_descriptions AS figure_descriptions\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 12, offset: 35} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN ID(n) AS source_id, ID(m) AS target_id\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 32, offset: 55} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN ID(n) AS source_id, ID(m) AS target_id\\n    '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.8145779967308044\n",
            "Epoch 10, Loss: 0.4602786898612976\n",
            "Epoch 20, Loss: 0.496256947517395\n",
            "Epoch 30, Loss: 0.4103090763092041\n",
            "Epoch 40, Loss: 0.44546693563461304\n",
            "Epoch 50, Loss: 0.4041920304298401\n",
            "Epoch 60, Loss: 0.4036252796649933\n",
            "Epoch 70, Loss: 0.3973328173160553\n",
            "Epoch 80, Loss: 0.427428275346756\n",
            "Epoch 90, Loss: 0.4420440196990967\n",
            "Enter your query (or type 'exit' to quit):\n",
            "Your query: What is project risk management?\n",
            "Great question! Regarding 'What is project risk management?', here's what I discovered:\n",
            "\n",
            "project management application knowledge skill tool technique project activity meet project requirement\n",
            "\n",
            "You might also find these related topics interesting:\n",
            "governance, rescue, surround, saving, delivery, organisation, bear upon, livery, organization, deliverance, encroachment, governing body, speech, brass, environment, obstetrical delivery, pitch, wallop, system, touch on, arrangement, establishment, constitution, touch, affect, environs, impingement, administration, surroundings, impact, bringing, legal transfer, manner of speaking, bear on, shock, formation\n",
            "Your query: Whar are the tools to ensure risk management?\n",
            "Great question! Regarding 'Whar are the tools to ensure risk management?', here's what I discovered:\n",
            "\n",
            "value delivery system\n",
            "\n",
            "You might also find these related topics interesting:\n",
            "design, shape, surround, count on, figure out, calculate, fancy, exploit, project, trope, frame, fig, solve, image, figure of speech, extremity, forecast, compute, body of work, work, member, envision, public figure, soma, human body, work out, physical body, name, employment, do work, cypher, cipher, exercise, work on, enter, oeuvre, act, bod, physique, workplace, make for, figure, sour, build, play, puzzle out, put to work, go, number, squad, fellow member, reckon, mould, visualize, study, function, pattern, knead, visualise, digit, environs, ferment, act upon, penis, mold, chassis, process, influence, see, crop, anatomy, make, estimate, operate, flesh, form, team, environment, wreak, team up, turn, appendage, forge, picture, surroundings, cultivate, run, phallus, material body, lick, piece of work, bring\n",
            "Your query: exit\n"
          ]
        }
      ],
      "source": [
        "from neo4j import GraphDatabase\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from transformers import pipeline\n",
        "\n",
        "# Establish connection to Neo4j\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Step 1: Fetch Data from Neo4j\n",
        "def fetch_graph_data():\n",
        "    nodes = {}\n",
        "    edge_index = []\n",
        "\n",
        "    # Fetch all nodes from Neo4j\n",
        "    node_query = \"\"\"\n",
        "    MATCH (n)\n",
        "    RETURN ID(n) AS node_id, labels(n) AS labels, n.name AS name, n.definition AS definition, n.synonyms AS synonyms, n.figure_descriptions AS figure_descriptions\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        node_results = session.run(node_query)\n",
        "        for record in node_results:\n",
        "            node_id = record[\"node_id\"]\n",
        "            nodes[node_id] = {\n",
        "                \"name\": record.get(\"name\", \"\"),\n",
        "                \"definition\": record.get(\"definition\", \"\"),\n",
        "                \"synonyms\": record.get(\"synonyms\", []),\n",
        "                \"figure_descriptions\": record.get(\"figure_descriptions\", []),\n",
        "                \"index\": len(nodes)  # Assign a unique index to each node\n",
        "            }\n",
        "\n",
        "    # Fetch all relationships from Neo4j\n",
        "    relationship_query = \"\"\"\n",
        "    MATCH (n)-[r]->(m)\n",
        "    RETURN ID(n) AS source_id, ID(m) AS target_id\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        relationship_results = session.run(relationship_query)\n",
        "        for record in relationship_results:\n",
        "            source_id = record[\"source_id\"]\n",
        "            target_id = record[\"target_id\"]\n",
        "\n",
        "            # Ensure that both source and target nodes are present in the graph\n",
        "            if source_id in nodes and target_id in nodes:\n",
        "                edge_index.append([nodes[source_id][\"index\"], nodes[target_id][\"index\"]])\n",
        "            else:\n",
        "                print(f\"Warning: Relationship between '{source_id}' and '{target_id}' refers to non-existent nodes.\")\n",
        "\n",
        "    return nodes, edge_index\n",
        "\n",
        "# Step 2: Prepare PyTorch Geometric Data\n",
        "def prepare_graph_data(nodes, edge_index):\n",
        "    # Define node features (for simplicity, using one-hot encoding for each node)\n",
        "    num_nodes = len(nodes)\n",
        "    features = torch.eye(num_nodes)  # One-hot encoding for each node\n",
        "\n",
        "    # Convert edge_index to tensor format\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Create the PyTorch Geometric Data object\n",
        "    data = Data(x=features, edge_index=edge_index)\n",
        "    return data\n",
        "\n",
        "# Fetch graph data from Neo4j\n",
        "nodes, edge_index = fetch_graph_data()\n",
        "data = prepare_graph_data(nodes, edge_index)\n",
        "\n",
        "# Step 3: Define the GCN Encoder Model\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and optimizer\n",
        "in_channels = data.num_node_features\n",
        "out_channels = 64  # Dimension of output embeddings\n",
        "model = GCNEncoder(in_channels, out_channels)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 4: Train the Model\n",
        "def train_embedding_model(epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        z = model(data.x, data.edge_index)  # Forward pass to get node embeddings\n",
        "\n",
        "        # Use positive edges from edge_index\n",
        "        positive_edges = data.edge_index\n",
        "\n",
        "        # Generate negative samples (corrupted edges)\n",
        "        num_nodes = data.num_nodes\n",
        "        negative_edges = torch.randint(0, num_nodes, positive_edges.size(), dtype=torch.long)\n",
        "\n",
        "        # Compute positive and negative scores\n",
        "        pos_score = F.cosine_similarity(z[positive_edges[0]], z[positive_edges[1]])\n",
        "        neg_score = F.cosine_similarity(z[negative_edges[0]], z[negative_edges[1]])\n",
        "\n",
        "        # Max-margin loss\n",
        "        margin = 1.0\n",
        "        loss = torch.mean(F.relu(margin - pos_score + neg_score))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "    return z\n",
        "\n",
        "# Train the embedding model\n",
        "embeddings = train_embedding_model()\n",
        "\n",
        "# Step 5: Define the Retrieval Function with Rich Context Generation\n",
        "def retrieve_relevant_context(query_embedding, node_embeddings, nodes, k=5):\n",
        "    # Compute similarity between the query and node embeddings (cosine similarity)\n",
        "    similarity_scores = F.cosine_similarity(query_embedding.unsqueeze(0), node_embeddings)\n",
        "    top_k_indices = torch.topk(similarity_scores, k).indices\n",
        "\n",
        "    context_details = []\n",
        "\n",
        "    for i in top_k_indices:\n",
        "        node_info = nodes[i.item()]\n",
        "        context_part = {\n",
        "            \"name\": node_info[\"name\"],\n",
        "            \"definition\": node_info[\"definition\"],\n",
        "            \"synonyms\": node_info[\"synonyms\"],\n",
        "            \"figure_descriptions\": node_info[\"figure_descriptions\"]\n",
        "        }\n",
        "        context_details.append(context_part)\n",
        "\n",
        "    return context_details\n",
        "\n",
        "# Example query embedding (you would typically generate this from a real query)\n",
        "query_embedding = embeddings[0]  # For demonstration purposes, use the first node embedding\n",
        "\n",
        "# Retrieve relevant nodes for context\n",
        "context_details = retrieve_relevant_context(query_embedding, embeddings, list(nodes.values()))\n",
        "\n",
        "# Step 6: Use HuggingFace's Question-Answering Pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Function to answer a query using the Hugging Face model\n",
        "def answer_query_with_context(query, context_details):\n",
        "    context = \"\"\n",
        "    related_topics = []\n",
        "\n",
        "    # Combine information from the context details\n",
        "    for item in context_details:\n",
        "        if item[\"definition\"]:\n",
        "            context += item[\"definition\"] + \" \"\n",
        "        if item[\"synonyms\"]:\n",
        "            related_topics.extend(item[\"synonyms\"])\n",
        "        if item[\"figure_descriptions\"]:\n",
        "            context += \" \".join(item[\"figure_descriptions\"]) + \" \"\n",
        "\n",
        "    # If context is not empty, generate an answer\n",
        "    if context.strip():\n",
        "        result = qa_pipeline(question=query, context=context)\n",
        "        response = f\"Great question! Regarding '{query}', here's what I discovered:\\n\\n{result['answer']}\\n\"\n",
        "    else:\n",
        "        response = f\"Thanks for your inquiry about '{query}'. Unfortunately, I couldn't find a specific answer this time.\\n\"\n",
        "\n",
        "    # Adding related topics for additional insight\n",
        "    if related_topics:\n",
        "        response += \"\\nYou might also find these related topics interesting:\\n\"\n",
        "        response += \", \".join(set(related_topics))\n",
        "\n",
        "    return response\n",
        "\n",
        "# Interactive Query Loop\n",
        "def interactive_query():\n",
        "    print(\"Enter your query (or type 'exit' to quit):\")\n",
        "    while True:\n",
        "        query = input(\"Your query: \")\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Generate a query embedding (for simplicity, using a random node's embedding)\n",
        "        query_embedding = embeddings[torch.randint(0, len(embeddings), (1,)).item()]\n",
        "\n",
        "        # Retrieve relevant nodes for context\n",
        "        context_details = retrieve_relevant_context(query_embedding, embeddings, list(nodes.values()))\n",
        "\n",
        "        # Get the answer from the QA model\n",
        "        response = answer_query_with_context(query, context_details)\n",
        "        print(response)\n",
        "\n",
        "# Example usage of the interactive function\n",
        "interactive_query()\n",
        "\n",
        "# Close the Neo4j connection\n",
        "driver.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation"
      ],
      "metadata": {
        "id": "nMa1IrhooAWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Neo4j connection details\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Function to extract keywords from a query\n",
        "def extract_keywords(query):\n",
        "    # Simple extraction by splitting on spaces and removing common words\n",
        "    query = query.lower()\n",
        "    stopwords = {\"how\", \"what\", \"is\", \"a\", \"an\", \"the\", \"to\", \"in\", \"on\", \"and\", \"or\", \"for\"}\n",
        "    words = re.findall(r'\\w+', query)\n",
        "    keywords = [word for word in words if word not in stopwords]\n",
        "    return keywords\n",
        "\n",
        "# Fetch related data from Neo4j\n",
        "def fetch_related_data(query_terms):\n",
        "    nodes = []\n",
        "    relationships = []\n",
        "\n",
        "    # Convert query terms list to lowercase to ensure case-insensitive matching\n",
        "    lower_query_terms = [term.lower() for term in query_terms]\n",
        "\n",
        "    # Fetch all nodes that match the query terms\n",
        "    node_query = \"\"\"\n",
        "    MATCH (n)\n",
        "    WHERE toLower(n.name) IN $query_terms OR any(syn IN n.synonyms WHERE toLower(syn) IN $query_terms)\n",
        "    RETURN n.name AS name, n.definition AS definition, n.synonyms AS synonyms, n.figure_descriptions AS figure_descriptions\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        node_results = session.run(node_query, query_terms=lower_query_terms)\n",
        "        for record in node_results:\n",
        "            nodes.append({\n",
        "                \"name\": record[\"name\"],\n",
        "                \"definition\": record.get(\"definition\", \"\"),\n",
        "                \"synonyms\": record.get(\"synonyms\", []),\n",
        "                \"figure_descriptions\": record.get(\"figure_descriptions\", [])\n",
        "            })\n",
        "\n",
        "    # Fetch relationships between the matched nodes (if needed)\n",
        "    relationship_query = \"\"\"\n",
        "    MATCH (n)-[r]->(m)\n",
        "    WHERE toLower(n.name) IN $query_terms OR any(syn IN n.synonyms WHERE toLower(syn) IN $query_terms)\n",
        "    RETURN type(r) AS relationship, m.name AS related_name\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        relationship_results = session.run(relationship_query, query_terms=lower_query_terms)\n",
        "        for record in relationship_results:\n",
        "            relationships.append({\n",
        "                \"relationship\": record[\"relationship\"],\n",
        "                \"related_name\": record[\"related_name\"]\n",
        "            })\n",
        "\n",
        "    return nodes, relationships\n",
        "\n",
        "# Build context from the graph data\n",
        "def build_context_from_graph_data(nodes, relationships):\n",
        "    context = \"\"\n",
        "    related_topics = []\n",
        "\n",
        "    # Build context from nodes\n",
        "    for node in nodes:\n",
        "        if node[\"definition\"]:\n",
        "            context += f\"Definition of {node['name']}: {node['definition']}.\\n\"\n",
        "        if node[\"figure_descriptions\"]:\n",
        "            context += f\"Figures related to {node['name']}: \" + \" \".join(node[\"figure_descriptions\"]) + \".\\n\"\n",
        "        if node[\"synonyms\"]:\n",
        "            related_topics.extend(node[\"synonyms\"])\n",
        "\n",
        "    # Build context from relationships\n",
        "    if relationships:\n",
        "        context += \"Relationships found:\\n\"\n",
        "        for rel in relationships:\n",
        "            context += f\"{rel['related_name']} ({rel['relationship']}).\\n\"\n",
        "\n",
        "    return context.strip(), related_topics\n",
        "\n",
        "# HuggingFace QA Pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Function to answer a query using the Hugging Face model\n",
        "def answer_query_with_context(query, context, related_topics):\n",
        "    # If context is available, use it to answer the question\n",
        "    if context:\n",
        "        result = qa_pipeline(question=query, context=context)\n",
        "        response = f\"Based on your query '{query}', I found the following information:\\n\\n{result['answer']}\\n\"\n",
        "    else:\n",
        "        response = f\"Based on your query '{query}', I couldn't find a specific answer.\\n\"\n",
        "\n",
        "    # Adding related topics for additional insight\n",
        "    if related_topics:\n",
        "        response += \"\\nAdditionally, here are some related topics that might interest you:\\n\"\n",
        "        response += \", \".join(set(related_topics))\n",
        "\n",
        "    return response\n",
        "\n",
        "# Evaluation Function for Retrieval\n",
        "def evaluate_retrieval(sample_queries, ground_truth_keywords):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for query in sample_queries:\n",
        "        # Extract keywords\n",
        "        query_terms = extract_keywords(query)\n",
        "\n",
        "        # Fetch nodes and relationships from Neo4j\n",
        "        nodes, relationships = fetch_related_data(query_terms)\n",
        "\n",
        "        # Build context and get related topics\n",
        "        context, related_topics = build_context_from_graph_data(nodes, relationships)\n",
        "\n",
        "        # Extracted keywords from the context (simulated here by looking at node names and synonyms)\n",
        "        extracted_keywords = [node[\"name\"] for node in nodes] + related_topics\n",
        "\n",
        "        # Ground-truth keywords for the query\n",
        "        true_keywords = ground_truth_keywords[query]\n",
        "\n",
        "        # Calculate precision and recall\n",
        "        if extracted_keywords:\n",
        "            true_positives = len(set(extracted_keywords) & set(true_keywords))\n",
        "            false_positives = len(set(extracted_keywords) - set(true_keywords))\n",
        "            false_negatives = len(set(true_keywords) - set(extracted_keywords))\n",
        "\n",
        "            precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "            recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "\n",
        "            precision_scores.append(precision)\n",
        "            recall_scores.append(recall)\n",
        "\n",
        "    avg_precision = np.mean(precision_scores) if precision_scores else 0\n",
        "    avg_recall = np.mean(recall_scores) if recall_scores else 0\n",
        "\n",
        "    return avg_precision, avg_recall\n",
        "\n",
        "# Evaluation Function for QA Generation\n",
        "def evaluate_qa_generation(sample_queries, qa_pipeline):\n",
        "    qualitative_feedback = []\n",
        "\n",
        "    for query in sample_queries:\n",
        "        # Extract keywords\n",
        "        query_terms = extract_keywords(query)\n",
        "\n",
        "        # Fetch nodes and relationships from Neo4j\n",
        "        nodes, relationships = fetch_related_data(query_terms)\n",
        "\n",
        "        # Build context from the graph data\n",
        "        context, related_topics = build_context_from_graph_data(nodes, relationships)\n",
        "\n",
        "        # Get the answer from the QA model\n",
        "        response = answer_query_with_context(query, context, related_topics)\n",
        "\n",
        "        # User feedback simulation (in real scenario, get it from human evaluators)\n",
        "        print(f\"\\nQuery: {query}\\nResponse: {response}\\n\")\n",
        "        user_feedback = input(\"Was this answer helpful? (yes/no): \").strip().lower()\n",
        "        qualitative_feedback.append(user_feedback)\n",
        "\n",
        "    # Calculate the percentage of positive feedback\n",
        "    positive_feedback_ratio = qualitative_feedback.count('yes') / len(qualitative_feedback)\n",
        "    return positive_feedback_ratio\n",
        "\n",
        "# Sample queries for evaluation related to risk management\n",
        "sample_queries = [\n",
        "    \"What is risk management?\",\n",
        "    \"How to identify project risks?\",\n",
        "    \"What strategies are effective for risk mitigation?\",\n",
        "    \"Define risk assessment.\",\n",
        "    \"What are the common types of project risks?\",\n",
        "    \"Explain the risk response planning process.\"\n",
        "]\n",
        "\n",
        "# Ground-truth keywords for each query related to risk management (typically come from experts or documentation)\n",
        "ground_truth_keywords = {\n",
        "    \"What is risk management?\": [\"risk management\", \"definition\", \"process\"],\n",
        "    \"How to identify project risks?\": [\"risk identification\", \"techniques\", \"methods\"],\n",
        "    \"What strategies are effective for risk mitigation?\": [\"risk mitigation\", \"strategies\", \"approaches\"],\n",
        "    \"Define risk assessment.\": [\"risk assessment\", \"evaluation\", \"analysis\"],\n",
        "    \"What are the common types of project risks?\": [\"types of risks\", \"financial\", \"operational\", \"technical\"],\n",
        "    \"Explain the risk response planning process.\": [\"risk response\", \"planning\", \"process\"]\n",
        "}\n",
        "\n",
        "# Main Evaluation Loop\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Evaluate Retrieval\n",
        "    avg_precision, avg_recall = evaluate_retrieval(sample_queries, ground_truth_keywords)\n",
        "    print(f\"\\nAverage Precision of Retrieval: {avg_precision:.2f}\")\n",
        "    print(f\"Average Recall of Retrieval: {avg_recall:.2f}\")\n",
        "\n",
        "    # Step 2: Evaluate QA Generation\n",
        "    positive_feedback_ratio = evaluate_qa_generation(sample_queries, qa_pipeline)\n",
        "    print(f\"\\nPercentage of Positive Feedback on QA Responses: {positive_feedback_ratio * 100:.2f}%\")\n",
        "\n",
        "    # Close Neo4j connection\n",
        "    driver.close()\n"
      ],
      "metadata": {
        "id": "qDb8Y7WHoBog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458d3965-86e8-4dca-ed0e-6d8695dff52f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Precision of Retrieval: 0.00\n",
            "Average Recall of Retrieval: 0.06\n",
            "\n",
            "Query: What is risk management?\n",
            "Response: Based on your query 'What is risk management?', I found the following information:\n",
            "\n",
            "organizational governance system governance system work alongside value delivery system\n",
            "\n",
            "Additionally, here are some related topics that might interest you:\n",
            "lay on the line, risk of exposure, danger, put on the line, gamble, hazard, endangerment, take a chance, take chances, management, risk of infection, adventure, run a risk, chance, peril, jeopardy, risk, direction\n",
            "\n",
            "Was this answer helpful? (yes/no): yes\n",
            "\n",
            "Query: How to identify project risks?\n",
            "Response: Based on your query 'How to identify project risks?', I found the following information:\n",
            "\n",
            "accept\n",
            "\n",
            "Additionally, here are some related topics that might interest you:\n",
            "architectural plan, compute, chassis, design, shape, envision, public figure, count on, number, contrive, see, anatomy, soma, human body, calculate, estimate, work out, physical body, name, fancy, project, flesh, reckon, cypher, trope, form, frame, programme, fig, cipher, program, be after, visualize, pattern, visualise, enter, image, plan, digit, picture, bod, physique, figure of speech, material body, figure, forecast, build\n",
            "\n",
            "Was this answer helpful? (yes/no): no\n",
            "\n",
            "Query: What strategies are effective for risk mitigation?\n",
            "Response: Based on your query 'What strategies are effective for risk mitigation?', I found the following information:\n",
            "\n",
            "\n",
            "risk (identify).\n",
            "resource (require).\n",
            "\n",
            "Additionally, here are some related topics that might interest you:\n",
            "lay on the line, risk of exposure, danger, put on the line, gamble, hazard, endangerment, take a chance, take chances, risk of infection, adventure, run a risk, chance, peril, jeopardy, risk\n",
            "\n",
            "Was this answer helpful? (yes/no): yes\n",
            "\n",
            "Query: Define risk assessment.\n",
            "Response: Based on your query 'Define risk assessment.', I found the following information:\n",
            "\n",
            "\n",
            "risk (identify\n",
            "\n",
            "Additionally, here are some related topics that might interest you:\n",
            "lay on the line, risk of exposure, danger, put on the line, gamble, hazard, endangerment, take a chance, take chances, risk of infection, adventure, run a risk, chance, peril, jeopardy, risk\n",
            "\n",
            "Was this answer helpful? (yes/no): no\n",
            "\n",
            "Query: What are the common types of project risks?\n",
            "Response: Based on your query 'What are the common types of project risks?', I found the following information:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Additionally, here are some related topics that might interest you:\n",
            "architectural plan, compute, chassis, design, shape, envision, public figure, count on, number, contrive, see, anatomy, soma, human body, calculate, estimate, work out, physical body, name, fancy, project, flesh, reckon, cypher, trope, form, frame, programme, fig, cipher, program, be after, visualize, pattern, visualise, enter, image, plan, digit, picture, bod, physique, figure of speech, material body, figure, forecast, build\n",
            "\n",
            "Was this answer helpful? (yes/no): no\n",
            "\n",
            "Query: Explain the risk response planning process.\n",
            "Response: Based on your query 'Explain the risk response planning process.', I found the following information:\n",
            "\n",
            "organizational governance system governance system work alongside value delivery system\n",
            "\n",
            "Additionally, here are some related topics that might interest you:\n",
            "body of work, put on the line, work, gamble, litigate, mold, shape, go, procedure, mental process, process, sue, risk of infection, peril, influence, figure out, crop, swear out, cognitive operation, summons, action, make, risk of exposure, risk, endangerment, work out, employment, operate, work on, exercise, exploit, form, do work, cognitive process, treat, jeopardy, mould, wreak, turn, unconscious process, forge, study, function, solve, knead, appendage, outgrowth, take a chance, oeuvre, act, physical process, serve, cultivate, chance, workplace, run, make for, ferment, operation, lay on the line, danger, hazard, lick, act upon, piece of work, march, sour, play, take chances, run a risk, puzzle out, bring, adventure, put to work\n",
            "\n",
            "Was this answer helpful? (yes/no): no\n",
            "\n",
            "Percentage of Positive Feedback on QA Responses: 33.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "jHlsInvhqVX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In this notebook, we developed a **GCN-based Deep Graph Infomax (DGI)** model to learn node embeddings for project risk management. We successfully implemented a query handling system that generates contextually relevant responses using graph-based node information.\n",
        "\n",
        "### Planned Enhancements\n",
        "To improve our system, we will:\n",
        "- Integrate a more advanced text generation model to reformulate answers in a more personalized manner.\n",
        "- Enhance context awareness to better capture user intent.\n",
        "- Utilize advanced NLP techniques for nuanced responses.\n",
        "\n",
        "These enhancements aim to create a more intelligent and user-friendly tool for effectively addressing project risk management inquiries.\n"
      ],
      "metadata": {
        "id": "ODiOG3ELqcyO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}